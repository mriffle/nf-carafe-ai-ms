/**
 * # Parameters for nf-maccoss-trex
 *
 * A NextFlow pipeline for analyzing data-ind
 */
params {
    /** \group{Input/Output Parameters} */

    // the format of the output spectral library, must be one of
    // 'diann' or 'encyclopedia' Default: 'diann'
    output_format = 'diann'

    // if this is set, diann-will be skipped and these results will be used
    // for example, results.tsv from DIA-NN
    peptide_results_file = null  

    // the data to be search
    spectra_file = null      // path to the raw or mzML file to be processed
    
    // parameters related to DIA-NN
    diann_image_override = null            // set to a name of a local docker image to use. e.g., 'diann:1.9.2'
    diann_fasta_file = null      // FASTA file used by DIA-NN
    diann_params = '--unimod4 --qvalue 0.01 --cut \'K*,R*,!*P\' --reanalyse --smart-profiling'

    // parameters related to Carafe
    carafe_fasta_file = null     // FASTA used by Carafe, if set to null will use diann_fasta_file
    carafe_cli_options = ''      // if set, these command line options will be used by Carafe 
                                 // note: the workflow sets the -db and -i parameters, do not set these

    // parameters related to msconvert
    msconvert.do_demultiplex = true;          // whether or not to demultiplex with msconvert
    msconvert.do_simasspectra = true;         // whether or not to do simAsSpectra with msconvert

    // general workflow params, can be changed
    result_dir = 'results/nf-carafe-ai-ms' /** \type{str} Where results will be saved. */
    report_dir = 'reports/nf-carafe-ai-ms' /** \type{str} Where results will be saved. */

    email = null

    // AWS Batch params
    aws.region = 'us-west-2'
    aws.batch.cliPath = '/usr/local/aws-cli/v2/current/bin/aws'
    aws.batch.logsGroup = '/batch/tei-nextflow-batch'
    aws.batch.maxConnections = 20
    aws.batch.connectionTimeout = 10000
    aws.batch.uploadStorageClass = 'INTELLIGENT_TIERING'
    aws.batch.storageEncryption = 'AES256'
    aws.batch.retryMode = 'standard'

}

plugins {
    id 'nf-amazon'
}

docker {
    enabled = true
}

aws {

    batch {
        // NOTE: this setting is only required if the AWS CLI tool is installed in a custom AMI
        cliPath = params.aws.batch.cliPath
        logsGroup = params.aws.batch.logsGroup
        maxConnections = params.aws.batch.maxConnections
        connectionTimeout = params.aws.batch.connectionTimeout
        uploadStorageClass = params.aws.batch.uploadStorageClass
        storageEncryption = params.aws.batch.storageEncryption
        retryMode = params.aws.batch.retryMode
    }

    region = params.aws.region
}

// Execution Profiles
profiles {

    /*
     * Params for running pipeline on the local computer (e.g.:
     * your laptop). These can be overridden in the local config file.
     */
    standard {
        process.executor = 'local'

        // limit nextflow to running 1 task at a time
        executor.queueSize = 1

        params.max_memory = '12.GB'
        params.max_cpus = 8
        params.max_time = '240.h'

        // where to cache mzml files after running msconvert
        params.mzml_cache_directory = '/data/mass_spec/nextflow/nf-carafe-ai-ms/mzml_cache'
        params.panorama_cache_directory = '/data/mass_spec/nextflow/panorama/raw_cache'
    }

    aws {
        process.executor = 'awsbatch'
        process.queue = 'nextflow_basic_ec2'

        // params for running pipeline on aws batch
        // These can be overridden in local config file

        // max params allowed for your AWS Batch compute environment
        params.max_memory = '250.GB'
        params.max_cpus = 32
        params.max_time = '240.h'

        // where to cache mzml files after running msconvert
        params.mzml_cache_directory = 's3://mc-tei-rex-nextflow-dda/dia/mzml_cache'
        params.panorama_cache_directory = 's3://mc-tei-rex-nextflow-dda/panorama_cache'
    }

    slurm {
        process.executor = 'slurm'

        params.max_memory = '12.GB'
        params.max_cpus = 8
        params.max_time = '240.h'

        // where to cache mzml files after running msconvert
        params.mzml_cache_directory = '/data/mass_spec/nextflow/nf-carafe-ai-ms/mzml_cache'
        params.panorama_cache_directory = '/data/mass_spec/nextflow/panorama/raw_cache'
    }

}

// Manifest
manifest {
    name            = 'nf-carafe-ai-ms'
    author          = 'Michael Riffle'
    homePage        = 'https://github.com/mriffle/nf-carafe-ai-ms'
    description     = 'Workflow for Carafe spectral library generation using the awesome power of AI'
    mainScript      = 'main.nf'
    nextflowVersion = '!>=21.10.3'
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']
def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
timeline {
    enabled = true
    file    = "${params.report_dir}/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.report_dir}/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    file    = "${params.report_dir}/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = false
    file    = "${params.report_dir}/pipeline_dag_${trace_timestamp}.html"
}

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'

// Load the images to use for all processes
includeConfig 'container_images.config'

// Function to ensure that resource requirements don't go beyond
// a maximum limit. Copied from the nf-core template.
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
